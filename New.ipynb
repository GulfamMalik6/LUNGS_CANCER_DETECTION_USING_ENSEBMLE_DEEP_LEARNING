{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjkeZNIm08Lv"
      },
      "source": [
        "# **_Initial Stage_**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibkeMIxI7kND"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D_PcL7x7kNE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "dataset_directory = '/content/drive/MyDrive/Officialdataset'\n",
        "\n",
        "for dirname, _, filenames in os.walk(dataset_directory):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gMZktrxhYAWb"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WN3msdb7kNE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import cv2\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "import io\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVHi15Cj7kNE"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "image_size = 150\n",
        "labels = ['Normal','Malignant','Benign']\n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/drive/MyDrive/Officialdataset (AUGMENTED)/Traning',i)\n",
        "    for j in os.listdir(folderPath):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size,image_size))\n",
        "        X_train.append(img)\n",
        "        Y_train.append(i)\n",
        "\n",
        "for i in labels:\n",
        "    folderPath = os.path.join('/content/drive/MyDrive/Officialdataset (AUGMENTED)/Testing',i)\n",
        "    for j in os.listdir(folderPath):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size,image_size))\n",
        "        X_train.append(img)\n",
        "        Y_train.append(i)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE7_OWeT7kNE"
      },
      "outputs": [],
      "source": [
        "X_train,Y_train = shuffle(X_train,Y_train,random_state=101)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCfZclht7kNF"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X_train,Y_train,test_size=0.3,random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWTuFXS67kNF"
      },
      "outputs": [],
      "source": [
        "y_train_new = []\n",
        "for i in y_train:\n",
        "    y_train_new.append(labels.index(i))\n",
        "y_train=y_train_new\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "\n",
        "y_test_new = []\n",
        "for i in y_test:\n",
        "    y_test_new.append(labels.index(i))\n",
        "y_test=y_test_new\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8h0koWD_VFn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***MODEL 1***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v95QtM7iPGNC"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu',input_shape=(150,150,3)))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(Conv2D(256,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation = 'relu'))\n",
        "model.add(Dense(512,activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(3,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6qqA-yWPdW-"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHgEmk7iLRpq"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyNQgJYoPjUc"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.3, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4XG1zk4Pl9H"
      },
      "outputs": [],
      "source": [
        "# Extract accuracy values from the history object\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Create a range of epochs\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epochs, train_accuracy, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_accuracy, 'b', label=\"Validation Accuracy\")\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wGeK2DlTzOD"
      },
      "outputs": [],
      "source": [
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create a range of epochs\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epochs, train_loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNig_85VcQCL"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path, target_size=(150, 150)):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img_array = np.array(img)\n",
        "    img_array = img_array.reshape(1, target_size[0], target_size[1], 3)\n",
        "    return img_array\n",
        "\n",
        "# Specify the path to the image\n",
        "image_path = '/content/drive/MyDrive/Officialdataset (AUGMENTED)/Testing/Benign/Benign_original_Bengin case (104).jpg_c06894e7-6305-477b-b5c4-8c3868c9fdf2.jpg'\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_array = load_and_preprocess_image(image_path)\n",
        "\n",
        "# Display the image\n",
        "img = image.load_img(image_path)\n",
        "plt.imshow(img, interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzozGS7C_XZt"
      },
      "outputs": [],
      "source": [
        "a = model.predict(img_array)\n",
        "predicted_class = a.argmax()\n",
        "\n",
        "# Define a dictionary to map class numbers to tumor information\n",
        "tumor_info = {\n",
        "    0: {\n",
        "        'name': 'Normal',\n",
        "        'details': 'Normal lung tissue without cancerous growth.',\n",
        "        'precautions': 'No specific precautions needed.',\n",
        "        'treatment': 'No cancer treatment required.'\n",
        "    },\n",
        "    1: {\n",
        "        'name': 'Malignant',\n",
        "        'details': 'Cancerous growth in the lung with potential for metastasis.',\n",
        "        'precautions': 'Seek immediate medical attention. Avoid smoking and exposure to carcinogens.',\n",
        "        'treatment': 'Treatment options include surgery, chemotherapy, and radiation therapy.'\n",
        "    },\n",
        "    2: {\n",
        "        'name': 'Benign',\n",
        "        'details': 'Non-cancerous growth or tumor in the lung.',\n",
        "        'precautions': 'Monitor for any changes in health. Consult a healthcare professional.',\n",
        "        'treatment': 'Treatment may be required only if the tumor causes symptoms.'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display tumor information based on the predicted class\n",
        "print(\"Predicted Tumor Type:\", tumor_info[predicted_class]['name'])\n",
        "print(\"Details:\", tumor_info[predicted_class]['details'])\n",
        "print(\"Precautions:\", tumor_info[predicted_class]['precautions'])\n",
        "print(\"Treatment:\", tumor_info[predicted_class]['treatment'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bajNZ8UqVkYs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "class_report = classification_report(y_true, y_pred_classes, target_names=labels)\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRTwgKTqRpii"
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix for Model 1 training set\n",
        "y_train_pred_model1 = model.predict(X_train)\n",
        "y_train_pred_classes_model1 = np.argmax(y_train_pred_model1, axis=1)\n",
        "confusion_mtx_model1 = confusion_matrix(np.argmax(y_train, axis=1), y_train_pred_classes_model1)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx_model1, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - Model 1 (Training Set)')\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report\n",
        "class_report_model1 = classification_report(np.argmax(y_train, axis=1), y_train_pred_classes_model1, target_names=labels)\n",
        "print(\"Classification Report - Model 1 (Training Set):\\n\", class_report_model1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvMuNfhS_N4f"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***MODEL 2***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YK4xPnOK4UG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4dj4DGlGsDv"
      },
      "outputs": [],
      "source": [
        "history2 = model2.fit(X_train, y_train, epochs=10, validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mya4KfCTIh9W"
      },
      "outputs": [],
      "source": [
        "# Accessing accuracy values for model2\n",
        "train_accuracy2 = history2.history['accuracy']\n",
        "val_accuracy2 = history2.history['val_accuracy']\n",
        "\n",
        "# Creating a range of epochs\n",
        "epochs = range(1, len(train_accuracy2) + 1)\n",
        "\n",
        "# Plotting training and validation accuracy for model2\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(epochs, train_accuracy2, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_accuracy2, 'b', label=\"Validation Accuracy\")\n",
        "plt.title('Training and Validation Accuracy (Model 2)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvuYBygUIoQG"
      },
      "outputs": [],
      "source": [
        "acc2 = history2.history['accuracy']\n",
        "val_acc2 = history2.history['val_accuracy']\n",
        "loss2 = history2.history['loss']\n",
        "val_loss2 = history2.history['val_loss']\n",
        "epochs = range(len(acc2))\n",
        "\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc2, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc2, 'b', label=\"Validation Accuracy\")\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss2, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss2, 'b', label=\"Validation Loss\")\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIGrpFa8IwS4"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the image\n",
        "image_path = '/content/drive/MyDrive/Officialdataset (AUGMENTED)/Testing/Benign/Benign_original_Bengin case (104).jpg_c06894e7-6305-477b-b5c4-8c3868c9fdf2.jpg'\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_array = load_and_preprocess_image(image_path)\n",
        "\n",
        "# Display the image\n",
        "img = image.load_img(image_path)\n",
        "plt.imshow(img, interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEekbgCAIzwI"
      },
      "outputs": [],
      "source": [
        "a = model2.predict(img_array)\n",
        "predicted_class2 = a.argmax()\n",
        "\n",
        "# Define a dictionary to map class numbers to tumor information\n",
        "tumor_info = {\n",
        "    0: {\n",
        "        'name': 'Normal',\n",
        "        'details': 'Normal lung tissue without cancerous growth.',\n",
        "        'precautions': 'No specific precautions needed.',\n",
        "        'treatment': 'No cancer treatment required.'\n",
        "    },\n",
        "    1: {\n",
        "        'name': 'Malignant',\n",
        "        'details': 'Cancerous growth in the lung with potential for metastasis.',\n",
        "        'precautions': 'Seek immediate medical attention. Avoid smoking and exposure to carcinogens.',\n",
        "        'treatment': 'Treatment options include surgery, chemotherapy, and radiation therapy.'\n",
        "    },\n",
        "    2: {\n",
        "        'name': 'Benign',\n",
        "        'details': 'Non-cancerous growth or tumor in the lung.',\n",
        "        'precautions': 'Monitor for any changes in health. Consult a healthcare professional.',\n",
        "        'treatment': 'Treatment may be required only if the tumor causes symptoms.'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display tumor information based on the predicted class\n",
        "print(\"Predicted Tumor Type:\", tumor_info[predicted_class2]['name'])\n",
        "print(\"Details:\", tumor_info[predicted_class2]['details'])\n",
        "print(\"Precautions:\", tumor_info[predicted_class2]['precautions'])\n",
        "print(\"Treatment:\", tumor_info[predicted_class2]['treatment'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogJ2GUleIz0A"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "class_report = classification_report(y_true, y_pred_classes, target_names=labels)\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWGv_FNIIz3g"
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix for Model 2 training set\n",
        "y_train_pred_model2 = model2.predict(X_train)\n",
        "y_train_pred_classes_model2 = np.argmax(y_train_pred_model2, axis=1)\n",
        "confusion_mtx_model2 = confusion_matrix(np.argmax(y_train, axis=1), y_train_pred_classes_model2)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx_model2, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - Model 2 (Training Set)')\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report\n",
        "class_report_model2 = classification_report(np.argmax(y_train, axis=1), y_train_pred_classes_model2, target_names=labels)\n",
        "print(\"Classification Report - Model 2 (Training Set):\\n\", class_report_model2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtcQiDcb9wlp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***MODEL 3***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3LE2F29-ACh"
      },
      "outputs": [],
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model3.summary()\n",
        "history3 = model3.fit(X_train,y_train,epochs=10,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3cJGBoViiHz"
      },
      "outputs": [],
      "source": [
        "3# Specify the path to the image\n",
        "image_path = '/content/drive/MyDrive/Officialdataset (AUGMENTED)/Testing/Benign/Benign_original_Bengin case (104).jpg_c06894e7-6305-477b-b5c4-8c3868c9fdf2.jpg'\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_array = load_and_preprocess_image(image_path)\n",
        "\n",
        "# Display the image\n",
        "img = image.load_img(image_path)\n",
        "plt.imshow(img, interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naUfHabjijYe"
      },
      "outputs": [],
      "source": [
        "a = model3.predict(img_array)\n",
        "predicted_class3 = a.argmax()\n",
        "\n",
        "# Define a dictionary to map class numbers to tumor information\n",
        "tumor_info = {\n",
        "    0: {\n",
        "        'name': 'Normal',\n",
        "        'details': 'Normal lung tissue without cancerous growth.',\n",
        "        'precautions': 'No specific precautions needed.',\n",
        "        'treatment': 'No cancer treatment required.'\n",
        "    },\n",
        "    1: {\n",
        "        'name': 'Malignant',\n",
        "        'details': 'Cancerous growth in the lung with potential for metastasis.',\n",
        "        'precautions': 'Seek immediate medical attention. Avoid smoking and exposure to carcinogens.',\n",
        "        'treatment': 'Treatment options include surgery, chemotherapy, and radiation therapy.'\n",
        "    },\n",
        "    2: {\n",
        "        'name': 'Benign',\n",
        "        'details': 'Non-cancerous growth or tumor in the lung.',\n",
        "        'precautions': 'Monitor for any changes in health. Consult a healthcare professional.',\n",
        "        'treatment': 'Treatment may be required only if the tumor causes symptoms.'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display tumor information based on the predicted class\n",
        "print(\"Predicted Tumor Type:\", tumor_info[predicted_class3]['name'])\n",
        "print(\"Details:\", tumor_info[predicted_class3]['details'])\n",
        "print(\"Precautions:\", tumor_info[predicted_class3]['precautions'])\n",
        "print(\"Treatment:\", tumor_info[predicted_class3]['treatment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1cZY-A7U-ZG"
      },
      "outputs": [],
      "source": [
        "# Generate confusion matrix for Model 3 training set\n",
        "y_train_pred_model3 = model3.predict(X_train)\n",
        "y_train_pred_classes_model3 = np.argmax(y_train_pred_model3, axis=1)\n",
        "confusion_mtx_model3 = confusion_matrix(np.argmax(y_train, axis=1), y_train_pred_classes_model3)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx_model3, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix - Model 3 (Training Set)')\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report\n",
        "class_report_model3 = classification_report(np.argmax(y_train, axis=1), y_train_pred_classes_model3, target_names=labels)\n",
        "print(\"Classification Report - Model 3 (Training Set):\\n\", class_report_model3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMwxRsOjR5jT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# ***Ensembling & Voting***\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMgwxXCF2cFH"
      },
      "outputs": [],
      "source": [
        "from statistics import mode\n",
        "\n",
        "# Make predictions using the three models\n",
        "predictions_model1 = model.predict(img_array)\n",
        "predictions_model2 = model2.predict(img_array)\n",
        "predictions_model3 = model3.predict(img_array)\n",
        "\n",
        "# Determine the class with the highest prediction confidence for each model\n",
        "class_model1 = np.argmax(predictions_model1)\n",
        "class_model2 = np.argmax(predictions_model2)\n",
        "class_model3 = np.argmax(predictions_model3)\n",
        "\n",
        "# Create a list to store the votes\n",
        "votes = [class_model1, class_model2, class_model3]\n",
        "\n",
        "# Use the mode function to find the most common class (the class with the most votes)\n",
        "ensemble_prediction = mode(votes)\n",
        "\n",
        "# Display tumor information based on the ensemble prediction\n",
        "print(\"Ensemble Predicted Tumor Type:\", tumor_info[ensemble_prediction]['name'])\n",
        "print(\"Details:\", tumor_info[ensemble_prediction]['details'])\n",
        "print(\"Precautions:\", tumor_info[ensemble_prediction]['precautions'])\n",
        "print(\"Treatment:\", tumor_info[ensemble_prediction]['treatment'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_njZlPwpW0Ig"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "def ensemble_predict(models, X):\n",
        "    # Get predictions from each model\n",
        "    predictions = [np.argmax(model.predict(X), axis=1) for model in models]\n",
        "\n",
        "    # Stack predictions and perform majority voting\n",
        "    predictions = np.stack(predictions, axis=1)\n",
        "    ensemble_prediction, _ = mode(predictions, axis=1)\n",
        "\n",
        "    return ensemble_prediction.ravel()\n",
        "\n",
        "# Assuming you have your models stored in a list\n",
        "models = [model, model2, model3]\n",
        "\n",
        "# Generate ensemble predictions on the test set\n",
        "ensemble_predictions = ensemble_predict(models, X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b25hrk7GW0MH"
      },
      "outputs": [],
      "source": [
        "# If y_test is one-hot encoded\n",
        "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "    y_test_single_label = np.argmax(y_test, axis=1)\n",
        "else:\n",
        "    y_test_single_label = y_test\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_single_label, ensemble_predictions)\n",
        "\n",
        "# Generate the classification report\n",
        "class_report = classification_report(y_test_single_label, ensemble_predictions, target_names=['Benign', 'Malignant', 'Normal'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Confusion Matrix for Ensemble Model:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "print(\"\\nClassification Report for Ensemble Model:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW55mD5NW0QH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Convert y_test to single-label format if it's one-hot encoded\n",
        "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
        "    y_test_single_label = np.argmax(y_test, axis=1)\n",
        "else:\n",
        "    y_test_single_label = y_test\n",
        "\n",
        "# Assuming 'class_report' is a string, we parse it into a pandas DataFrame\n",
        "report_data = []\n",
        "lines = class_report.split('\\n')\n",
        "for line in lines[2:-5]:\n",
        "    row_data = line.split()\n",
        "    report_data.append({\n",
        "        'Class': row_data[0],\n",
        "        'Precision': float(row_data[1]),\n",
        "        'Recall': float(row_data[2]),\n",
        "        'F1-Score': float(row_data[3]),\n",
        "        'Support': int(row_data[4])\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "report_df = pd.DataFrame.from_dict(report_data)\n",
        "\n",
        "# Add the overall accuracy at the bottom\n",
        "overall_accuracy = accuracy_score(y_test_single_label, ensemble_predictions)\n",
        "\n",
        "# Create the new row with the correct number of values\n",
        "new_row = pd.Series({\n",
        "    'Class': 'Overall',\n",
        "    'Precision': '-',\n",
        "    'Recall': '-',\n",
        "    'F1-Score': '-',\n",
        "    'Support': len(y_test_single_label)\n",
        "})\n",
        "\n",
        "# Convert the new_row to a DataFrame and concatenate it with the original DataFrame\n",
        "new_row_df = pd.DataFrame([new_row])\n",
        "report_df = pd.concat([report_df, new_row_df], ignore_index=True)\n",
        "\n",
        "# Add the overall accuracy as a new column\n",
        "report_df['Accuracy'] = overall_accuracy\n",
        "\n",
        "# Display the table\n",
        "print(report_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HZXsQInW0TO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have saved the values for training and validation accuracy in lists\n",
        "# Example lists:\n",
        "train_accuracies = [1.00, 0.99, 0.96]\n",
        "val_accuracies = [0.99, 0.98, 0.97]\n",
        "\n",
        "# Plotting the ensemble accuracy (use real values from your models)\n",
        "plt.plot(train_accuracies, label='Training Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.plot([overall_accuracy]*len(train_accuracies), label='Ensemble Accuracy', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqej5roiXSuj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Exclude the 'Overall' row to ensure we're only working with numeric values\n",
        "numeric_df = report_df[report_df['Precision'] != '-']\n",
        "\n",
        "# Plotting the ensemble precision, recall, and F1-score\n",
        "metrics = ['Precision', 'Recall', 'F1-Score']\n",
        "values = numeric_df[metrics].astype(float).mean().values\n",
        "\n",
        "plt.plot(metrics, values, marker='o')\n",
        "plt.title('Ensemble Model Performance')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
